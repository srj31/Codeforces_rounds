{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6. Optimization. Programming Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the **House Pricing** dataset, where you have a lot of information about the houses being sold and you aim to produce the price of the house. \n",
    "\n",
    "Firstly, let us import basic libraries (`numpy` ([docs](https://numpy.org/)) for matrix operations and `pandas` ([docs](https://pandas.pydata.org/)) for convinient dataset workaround):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1. Reading and Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datX=np.load('x_train.npy')\n",
    "datY=np.log(np.load('y_train.npy'))\n",
    "datX=pd.DataFrame(datX, columns=datX.dtype.names)\n",
    "datX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we manage to load the data (you can read more about the `load` [here](https://docs.scipy.org/doc/numpy/reference/generated/numpy.load.html). But it is not a necessity). We are going to use linear models to work with it, but firstly we need to come up with idea what features should we include in the model at all (which feature the price is lineary dependent on):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not forget to install seaborn. You can do that by running `pip install seaborn` in the command line locally, or simply by running the next sell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do it let us plot every feature vs the price. Firstly, we import nice plotting modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax=plt.subplots(4, 4, figsize=(16,16))\n",
    "\n",
    "for i, name in enumerate(datX.columns):\n",
    "    ax[i//4][i%4].scatter(datX[name], y)\n",
    "    ax[i//4][i%4].set_title(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us say, that we choose to work the following set of features:\n",
    "+ `bedrooms`\n",
    "+ `bathrooms`\n",
    "+ `sqft_living`\n",
    "+ `floors`\n",
    "+ `condition`\n",
    "+ `grade`\n",
    "+ `sqft_above`\n",
    "+ `sqft_basement`\n",
    "+ `long`\n",
    "+ `lat`\n",
    "\n",
    "Clear the dataset from all the other features and create:\n",
    "1. matrix $X$, all elements should be real numbers\n",
    "2. number $N$ -- number of considered houses\n",
    "3. number $m$ -- number of new features\n",
    "\n",
    "**Hint**: it is easier to clean columns from dataset (you should look [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html) for insipration) and the get a matrix with `.values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code goes here\n",
    "X=...\n",
    "N=...\n",
    "m=..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to automatically check results of your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checker import Reader\n",
    "Reader(X,N,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider that we are interested in the loss of the model we discussed in the video:\n",
    "\n",
    "+ Assume we have input data that is denoted as $\\vec{x}_1, \\vec{x}_2, \\ldots, \\vec{x}_N$\n",
    "+ House prices for this input data are known $y_1, y_2, \\ldots, y_N$\n",
    "\n",
    "We propose a **simple linear model** for this task:\n",
    "\n",
    "$$ \\hat{y}_i=w_0+w_1x_1+w_2x_2+\\ldots+w_mx_m $$\n",
    "\n",
    "As a loss function we will use the mean squared error (**MSE**):\n",
    "\n",
    "$$\n",
    "Loss(\\vec{w})=\\frac{1}{N}\\sum_{i=1}^N (y_i-\\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "### Task 2. Compute analytically the $Loss(\\vec{w})$ function\n",
    "Please, keep the signature of the function and enter the code only under `your code goes here`. \n",
    "**Attention**: try to avoid usage of `for` cycles! The easiest way to do it is by using matrix operations.\n",
    "\n",
    "_Hint_: to get nice $w_0$ coefficient it is convinient to add to the `X` matrix the column of 1 with `np.concatenate` [documentation](https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(w, X, y):\n",
    "    #your code goes here\n",
    "  \n",
    "    return lossValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to automatically check results of your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checker import lossOK\n",
    "lossOK(loss, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3. Compute analyticaly the gradient of the $Loss(\\vec{w})$\n",
    "Please, enter your answer in the cell below (it should be a `markdown` cell). You can either specify each partial derivative $\\frac{\\partial Loss}{\\partial w_i}$ or $\\nabla Loss$ altogether using matrix operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4. Write a function to compute the gradient of the Loss function in the given point\n",
    "Please, keep the signature of the function and enter the code only under `your code goes here`. \n",
    "**Attention**: try to avoid usage of `for` cycles! The easiest way to do it is by using matrix operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(w_k, X, y):\n",
    "    #your code goes here\n",
    "    \n",
    "    return lossGradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to automatically check your function. You will also see time comparison: if your function works sufficiently slower, you probably should think of faster alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checker import gradOK    \n",
    "gradOK(grad, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5. Write gradient descent\n",
    "How it is time to formulate the gradient descent! As you remeember, the idea here is that:\n",
    "$$\n",
    "\\vec{w}^{k+1}=\\vec{w}^{k}-\\alpha_k\\cdot \\nabla Loss(\\vec{w}^{k}\n",
    "$$\n",
    "We propose that you use constant $\\alpha_k=\\alpha$. Assume that the method should stop in two cases:\n",
    "+ if the number of iterations is to high (`maxiter`)\n",
    "+ if the length of the gradient is low enough (<`eps`) to call an extremum\n",
    "\n",
    "Please, keep the signature of the function and enter the code only under `your code goes here`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradDescent(w_init, alpha, X, y, maxiter=500, eps=1e-2):\n",
    "    losses=[]\n",
    "    weights=[w_init]\n",
    "    \n",
    "    curiter=0\n",
    "    w_k=weights[-1]\n",
    "    \n",
    "    #your code goes here\n",
    "    while ...:\n",
    "        w_k=...\n",
    "        lossValue_k=...\n",
    "        \n",
    "        weights.append(w_k)\n",
    "        losses.append(lossValue_k)\n",
    "        \n",
    "    return weights, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with several alphas and several intial values of weights. To illustrate, provide graphs for the Loss function over iterations in each case (and, optionally, the distance between weigths from one iteration to the next):\n",
    "\n",
    "(we provided all key plotting commands for you, but you can always look into [this tutorial](https://matplotlib.org/tutorials/introductory/usage.html#sphx-glr-tutorials-introductory-usage-py))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "#your code goes here\n",
    "\n",
    "plt.plot(...)\n",
    "plt.xlabel(...)\n",
    "plt.ylabel(...)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the adequacy of the model we created.\n",
    "\n",
    "Choose several (no less then five) houses (inputs in your `X` matrix) and calculte predicted prices by:\n",
    "\n",
    "$$ \\hat{y}_i=w_0+w_1x_1+w_2x_2+\\ldots+w_mx_m $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare predicted values with an actual answer (stored in your `y` array). Is it satisfying enough?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6. Discussion\n",
    "Answer following questions:\n",
    "1. Does your method converge at least for some alpha? If not, what might be the workaround?\n",
    "2. How does changing of the alpha influence the speed of convergence?\n",
    "3. Are the optimal weights in all convergent cases the same?\n",
    "4. How does this affect the Loss function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}